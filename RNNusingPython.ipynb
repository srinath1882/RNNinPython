{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645cb96f-8fc5-476a-d16f-2fa18d937587"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10224 characters, 76 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1.0/(1 + np.exp(-x))# write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  #f = 1.0/(1 + np.exp(-y))\n",
        "  return (y * (1 - y))# write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  #return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))# write your code here\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  #f = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "  return 1 - y**2 # write your code here"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6cLp8VRXkKd",
        "outputId": "33dd716a-332b-4dbc-eb80-c707b1ab9995"
      },
      "source": [
        "# Quiz Question 1\n",
        "sigmoid(0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPo0DOaFXlZU",
        "outputId": "cebc0604-72d7-42fd-e3de-da44bbe774c7"
      },
      "source": [
        "dsigmoid(sigmoid(0)) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA9Wc_VBXmrU",
        "outputId": "448e9553-d69d-4cb7-874f-0baaf30c4493"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ-dsUnrXoJL",
        "outputId": "c0c7d997-5de0-431d-dab9-5628018308de"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0)))) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z )+ p.b_f.v) # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)# write your code here\n",
        "\n",
        "    C = np.multiply(f,  C_prev) + np.multiply(i, C_bar)# write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_i.v) # write ur code here\n",
        "    h = o * tanh(C)# write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZj0fMcuXxpb",
        "outputId": "c9f38873-3da5-490c-ffe1-3f8f51287f2b"
      },
      "source": [
        "# Quiz Question 5\n",
        "\n",
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqwqXQT2X0wc",
        "outputId": "161f7aab-b699-4f2e-e28d-4be794fcbd04"
      },
      "source": [
        "#Quiz Question 6\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "4dbd573f-bd5e-42f5-ad36-e296d32be4c2"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "  Wohble wist and warmmmech poredine for MERS in lation and in 2aching in 1achich. She is hospita. In utrical with people whow rheidly your erepien sparied in Chinfirn. On a Coronavirus?\n",
            "Coronaviruses  \n",
            "----\n",
            "iter 49900, loss 5.345752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}